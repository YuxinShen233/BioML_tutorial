{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models have become essential tools for learning complex patterns in biological sequences. Unlike linear or traditional nonlinear models, deep architectures can directly learn hierarchical features from raw sequences, capturing both local motifs and long-range dependencies.\n",
    "In this notebook, we explore two major deep learning families widely used in computational biology: CNN and Transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:11:58.780517Z",
     "start_time": "2025-11-28T00:11:58.176716Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:11:59.261311Z",
     "start_time": "2025-11-28T00:11:58.781653Z"
    }
   },
   "outputs": [],
   "source": [
    "CAPSD = pd.read_csv(\"data_fitness/CAPSD_AAV2S_Sinai_2021.csv\")\n",
    "PHOT = pd.read_csv(\"data_fitness/PHOT_CHLRE_Chen_2023.csv\")\n",
    "POLG = pd.read_csv(\"data_fitness/POLG_DEN26_Suphatrakul_2023.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first process the data from CAPSD dataset, doing one-hot encoding for the amino acid sequences and then the train-test split. We take the first 5000 entries to keep runtime manageable.\n",
    "\n",
    "mutated_sequence contains amino acid sequences.\n",
    "\n",
    "DMS_score is the experimentally measured fitness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:11:59.264124Z",
     "start_time": "2025-11-28T00:11:59.262227Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = CAPSD[\"mutated_sequence\"].values[:5000]\n",
    "scores = CAPSD[\"DMS_score\"].values[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:00.309455Z",
     "start_time": "2025-11-28T00:11:59.265007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 14700)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\") \n",
    "encoder = OneHotEncoder(categories=[amino_acids] * len(sequences[0]))\n",
    "seq_list = [list(seq) for seq in sequences]\n",
    "X = encoder.fit_transform(seq_list)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an 80/20 train–test split. Since fitness values vary in scale, we apply StandardScaler to the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:00.426917Z",
     "start_time": "2025-11-28T00:12:00.322059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4000, 14700), (1000, 14700))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train_noscale, y_test_noscale = train_test_split(\n",
    "    X, scores, test_size=0.2, random_state=42)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train= y_scaler.fit_transform(y_train_noscale.reshape(-1, 1)).ravel()\n",
    "\n",
    "y_test = y_scaler.transform(y_test_noscale.reshape(-1, 1)).ravel()\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define the helper function to print different metrics for evaluating machine learning models on the held-out test set:\n",
    "\n",
    "-R2 score (coefficient of determination)\n",
    "\n",
    "-Mean Squared Error (MSE)\n",
    "\n",
    "-Mean Absolute Error (MAE)\n",
    "\n",
    "Higher R2 score, lower MSE and MAE indicate a better machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, y_true, y_pred):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"R2:\", r2_score(y_true, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
    "    print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep learning models can be built with the PyTorch package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:01.027680Z",
     "start_time": "2025-11-28T00:12:00.427679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:01.365711Z",
     "start_time": "2025-11-28T00:12:01.028887Z"
    }
   },
   "outputs": [],
   "source": [
    "if not isinstance(X_train, np.ndarray):\n",
    "    X_train = X_train.toarray()\n",
    "\n",
    "if not isinstance(X_test, np.ndarray):\n",
    "    X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:01.371299Z",
     "start_time": "2025-11-28T00:12:01.367225Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_dim = 20\n",
    "seq_len = X_train.shape[1] // feature_dim   \n",
    "\n",
    "\n",
    "assert X_train.shape[1] == seq_len * feature_dim, \\\n",
    "    \"Input dimension is not divisible by 20. Check one-hot encoding!\"\n",
    "\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, X, y, seq_len, feature_dim=20):\n",
    "        \"\"\"\n",
    "        X: numpy array (N, seq_len * feature_dim)\n",
    "        y: numpy array (N,)\n",
    "        \"\"\"\n",
    "        # reshape into (N, seq_len, 20)\n",
    "        self.X = X.reshape(-1, seq_len, feature_dim)\n",
    "        self.y = y.astype(float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.X[idx], dtype=torch.float32),\n",
    "            torch.tensor(self.y[idx], dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "\n",
    "train_ds = SequenceDataset(X_train, y_train, seq_len)\n",
    "test_ds  = SequenceDataset(X_test,  y_test,  seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:12:01.447346Z",
     "start_time": "2025-11-28T00:12:01.372196Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model_torch(name, model, loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    trues = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            out = model(Xb).cpu().numpy()\n",
    "            preds.append(out)\n",
    "            trues.append(yb.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    trues = np.concatenate(trues)\n",
    "    evaluate_model(name, trues, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:44:07.432255Z",
     "start_time": "2025-11-27T23:43:59.159430Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, seq_len, feature_dim=20):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv1d(feature_dim, 64, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),   # seq_len → seq_len/2\n",
    "            nn.Conv1d(64, 128, kernel_size=5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2),   # seq_len/2 → seq_len/4\n",
    "        )\n",
    "\n",
    "        # ---- Compute flattened dimension automatically ----\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, feature_dim, seq_len)  # (batch, channels, length)\n",
    "            conv_out = self.conv(dummy)\n",
    "            self.flat_dim = conv_out.numel()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.flat_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq, features) → CNN needs (batch, channels, seq)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "cnn = CNNModel(seq_len).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:44:07.438490Z",
     "start_time": "2025-11-27T23:44:07.434178Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loader, lr=1e-3, epochs=20):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(Xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-27T23:44:25.204398Z",
     "start_time": "2025-11-27T23:44:07.440048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 65.9356\n",
      "Epoch 2 | Loss: 58.6360\n",
      "Epoch 3 | Loss: 42.7081\n",
      "Epoch 4 | Loss: 29.8048\n",
      "Epoch 5 | Loss: 22.5924\n",
      "Epoch 6 | Loss: 18.6759\n",
      "Epoch 7 | Loss: 16.5281\n",
      "Epoch 8 | Loss: 15.1806\n",
      "Epoch 9 | Loss: 13.8016\n",
      "Epoch 10 | Loss: 13.0996\n",
      "Epoch 11 | Loss: 12.5772\n",
      "Epoch 12 | Loss: 11.4877\n",
      "Epoch 13 | Loss: 11.0906\n",
      "Epoch 14 | Loss: 10.8290\n",
      "Epoch 15 | Loss: 9.8271\n",
      "Epoch 16 | Loss: 9.8749\n",
      "Epoch 17 | Loss: 9.1654\n",
      "Epoch 18 | Loss: 9.2720\n",
      "Epoch 19 | Loss: 8.8103\n",
      "Epoch 20 | Loss: 8.7256\n",
      "--- CNN ---\n",
      "R2: 0.8094356262246418\n",
      "MSE: 0.19345362\n",
      "MAE: 0.3309806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(cnn, train_loader, epochs=20)\n",
    "evaluate_model_torch(\"CNN\", cnn, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:16:39.983461Z",
     "start_time": "2025-11-28T00:16:38.924175Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=2048):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]\n",
    "\n",
    "\n",
    "class SmallDataConvTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_dim=20,      \n",
    "        d_model=64,          \n",
    "        conv_channels=32,    \n",
    "        kernel_size=5,\n",
    "        nhead=4,            \n",
    "        num_layers=2,        \n",
    "        dropout=0.2\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=feature_dim,\n",
    "            out_channels=conv_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=kernel_size // 2\n",
    "        )\n",
    "        self.conv_act = nn.ReLU()\n",
    "\n",
    "        self.proj = nn.Linear(conv_channels, d_model)\n",
    "\n",
    "\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "\n",
    "\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 2, \n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True               \n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(layer, num_layers=num_layers)\n",
    "\n",
    "        self.cls = nn.Parameter(torch.randn(1, 1, d_model))\n",
    "\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, _ = x.shape\n",
    "\n",
    "        x = x.transpose(1, 2)     \n",
    "        x = self.conv_act(self.conv(x))   \n",
    "        x = x.transpose(1, 2)   \n",
    "\n",
    "        x = self.proj(x)         \n",
    "        cls = self.cls.expand(B, 1, -1)\n",
    "        x = torch.cat([cls, x], dim=1)   \n",
    "\n",
    "        x = self.pos(x)\n",
    "        x = self.encoder(x)\n",
    "\n",
    "        cls_out = x[:, 0]\n",
    "        return self.fc(cls_out).squeeze(-1)\n",
    "transformer = SmallDataConvTransformer().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:17:55.927358Z",
     "start_time": "2025-11-28T00:17:55.924113Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, loader, lr=5e-5, epochs=20):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for Xb, yb in loader:\n",
    "            Xb = Xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(Xb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-28T00:18:48.503231Z",
     "start_time": "2025-11-28T00:17:56.056561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 62.9447\n",
      "Epoch 2 | Loss: 63.0223\n",
      "Epoch 3 | Loss: 62.9669\n",
      "Epoch 4 | Loss: 62.9909\n",
      "Epoch 5 | Loss: 63.0072\n",
      "Epoch 6 | Loss: 62.9863\n",
      "Epoch 7 | Loss: 63.0783\n",
      "Epoch 8 | Loss: 63.1228\n",
      "Epoch 9 | Loss: 62.9415\n",
      "Epoch 10 | Loss: 63.0506\n",
      "Epoch 11 | Loss: 62.9417\n",
      "Epoch 12 | Loss: 62.9909\n",
      "Epoch 13 | Loss: 63.0131\n",
      "Epoch 14 | Loss: 63.1710\n",
      "Epoch 15 | Loss: 62.9182\n",
      "Epoch 16 | Loss: 62.8425\n",
      "Epoch 17 | Loss: 63.0042\n",
      "Epoch 18 | Loss: 63.0392\n",
      "Epoch 19 | Loss: 62.8961\n",
      "Epoch 20 | Loss: 62.9396\n",
      "--- Transformer ---\n",
      "R2: -0.004772354686790381\n",
      "MSE: 1.0200063\n",
      "MAE: 0.8963697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(transformer, train_loader, epochs=20)\n",
    "evaluate_model_torch(\"Transformer\", transformer, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that CNN performance is good because the convolutional strucutre can capture the motifs in the amino acid sequences; but Transformer is not working, probably because of the small size of the data. Deep learning models are great, but not always useful, depending on the structure of the biological data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BioML-tut-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
